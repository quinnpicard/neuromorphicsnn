{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from encode import Chromagram\n",
    "from encode import Encoder\n",
    "import pickle\n",
    "\n",
    "import risp\n",
    "import neuro\n",
    "import eons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "\n",
    "all_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.wav')]\n",
    "\n",
    "def parse_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    parts = base_name.split('_')\n",
    "    chord_type = parts[1] \n",
    "    chord_name = parts[2]\n",
    "    root_note_name = parts[3]\n",
    "    return chord_type, chord_name, root_note_name\n",
    "\n",
    "labels = [parse_filename(fname) for fname in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dofo/Repos/Bitbucket/framework/pyframework/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=691\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spike_data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "\n",
    "\n",
    "for wav_path in all_files:\n",
    "    chroma = Chromagram(wav_path)\n",
    "    chroma_array = chroma.chromagram\n",
    "    \n",
    "    # Replicate the directory structure for spike data\n",
    "    relative_path = os.path.relpath(wav_path, data_dir)\n",
    "    spike_filename = os.path.join(spike_data_dir, relative_path.replace('.wav', '.npy'))\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(spike_filename), exist_ok=True)\n",
    "    \n",
    "    # Save the spike data to disk using pickle\n",
    "    np.save(spike_filename, chroma_array)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "\n",
    "chroma_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numerical_labels_for_root(labels):\n",
    "    # Extract root notes\n",
    "    root_notes = [root_note for _, root_note, _ in labels]\n",
    "    \n",
    "    # Get unique root notes and assign a unique number to each\n",
    "    unique_root_notes = sorted(list(set(root_notes)))\n",
    "    root_to_num = {root: i for i, root in enumerate(unique_root_notes)}\n",
    "    \n",
    "    # Convert root notes to numerical labels\n",
    "    numerical_labels = [root_to_num[root] for root in root_notes]\n",
    "    \n",
    "    return numerical_labels, root_to_num\n",
    "\n",
    "# Create numerical labels for root notes\n",
    "y, root_to_num = create_numerical_labels_for_root(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into training+validation and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(chroma_files, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# One-hot encode the labels\n",
    "OneHot = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = OneHot.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_encoded = OneHot.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_encoded = OneHot.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 88)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self,source_dir, destination_dir):\n",
    "\n",
    "        self.source_directory = source_dir\n",
    "        self.destination_directory = destination_dir\n",
    "        \n",
    "        self.all_files = self._get_all_files()\n",
    "        self.labels = self._generate_labels()\n",
    "\n",
    "    def _get_all_files(self):\n",
    "        return [os.path.join(root, fname)\n",
    "                for root, dirs, files in os.walk(self.source_dir)\n",
    "                for fname in files if fname.endswith('.wav')]\n",
    "\n",
    "    def _generate_labels(self):\n",
    "        return [self._parse_filename(fname) for fname in self.all_files]\n",
    "\n",
    "    def _parse_filename(self, filename):\n",
    "        base_name = os.path.basename(filename)\n",
    "        parts = base_name.split('_')\n",
    "        chord_type = parts[1] \n",
    "        chord_name = parts[2]\n",
    "        root_note_name = parts[3]\n",
    "        return chord_type, chord_name, root_note_name\n",
    "    \n",
    "    def save_npy_files(self):\n",
    "            for wav_path in self.all_files:\n",
    "                chroma = Chromagram(wav_path)\n",
    "                chroma_array = chroma.chromagram\n",
    "                \n",
    "                relative_path = os.path.relpath(wav_path, self.source_directory)\n",
    "                npy_filename = os.path.join(self.destination_directory, relative_path.replace('.wav', '.npy'))\n",
    "                \n",
    "                os.makedirs(os.path.dirname(npy_filename), exist_ok=True)\n",
    "                np.save(npy_filename, chroma_array)  \n",
    "\n",
    "    def create_numerical_labels_for_root(self):\n",
    "        # Extract root notes    \n",
    "        root_notes = [root_note for _, root_note, _ in self.labels]\n",
    "        # Get unique root notes and assign a unique number to each\n",
    "        unique_root_notes = sorted(list(set(root_notes)))\n",
    "        root_to_num = {root: i for i, root in enumerate(unique_root_notes)}\n",
    "        # Convert root notes to numerical labels\n",
    "        numerical_labels = [root_to_num[root] for root in root_notes]\n",
    "        return numerical_labels, root_to_num \n",
    "    \n",
    "    def save_labels(self, label_filename):\n",
    "        y, _ = self.create_numerical_labels_for_root()\n",
    "        with open(os.path.join(self.destination_directory, label_filename), 'w') as f:\n",
    "            for label in y:\n",
    "                f.write(f\"{label}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "risp_config = {\n",
    "  \"leak_mode\": \"all\",\n",
    "  \"min_weight\": -1,\n",
    "  \"max_weight\": 1,\n",
    "  \"min_threshold\": -1,\n",
    "  \"max_threshold\": 1,\n",
    "  \"max_delay\": 5,\n",
    "  \"discrete\": False\n",
    "}\n",
    "\n",
    "proc = risp.Processor(risp_config)\n",
    "\n",
    "net = neuro.Network()\n",
    "net.set_properties(proc.get_network_properties())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 12\n",
    "n_hidden = 100\n",
    "n_outputs = 88\n",
    "n_total = n_inputs + n_hidden + n_outputs\n",
    "\n",
    "moa = neuro.MOA()\n",
    "moa.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Node 0 already exists at specified index.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_inputs):\n\u001b[0;32m----> 2\u001b[0m     node \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49madd_node(i)\n\u001b[1;32m      3\u001b[0m     net\u001b[39m.\u001b[39madd_input(i)\n\u001b[1;32m      4\u001b[0m     net\u001b[39m.\u001b[39mrandomize_node_properties(moa,node)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Node 0 already exists at specified index."
     ]
    }
   ],
   "source": [
    "for i in range(n_inputs):\n",
    "    node = net.add_node(i)\n",
    "    net.add_input(i)\n",
    "    net.randomize_node_properties(moa,node)\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    node = net.add_node(n_inputs+i)\n",
    "    net.add_output(i)\n",
    "    net.randomize_node_properties(moa,node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_params = {\n",
    "    \"population_size\": 100,\n",
    "    \"starting_nodes\": n_total,\n",
    "    \"starting_edges\": n_total,\n",
    "    \"multi_edges\": 0.05,\n",
    "    \"merge_rate\": .01,\n",
    "    \"crossover_rate\": 0.5,\n",
    "    \"mutation_rate\": 0.9,\n",
    "    \"add_node_rate\": 0.5,\n",
    "    \"add_edge_rate\": 0.9,\n",
    "    \"delete_node_rate\": 0.4,\n",
    "    \"delete_edge_rate\": 0.8,\n",
    "    \"node_params_rate\": 1.5,\n",
    "    \"edge_params_rate\": 1.5,\n",
    "    \"net_params_rate\": .01,\n",
    "    \"num_mutations\": 5,\n",
    "    \"random_factor\": 0.05,\n",
    "    \"num_best\": 3,\n",
    "\n",
    "    \"selection_type\": \"tournament\",\n",
    "    \"tournament_size_factor\": 0.1,\n",
    "    \"tournament_best_net_factor\": 0.9,\n",
    "    \"node_mutations\": { \"Threshold\": 1.0 },\n",
    "    \"net_mutations\": { },\n",
    "    \"edge_mutations\": { \"Weight\": 0.5, \"Delay\": 0.5 },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolver = eons.EONS(eo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_spike = Encoder(ex1).spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 ='/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords/dom7_ninth/NordGrand1_dom7ninth_G3_55.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.load_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.apply_spikes(Encoder(ex1).spikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyframework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
