{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from encode import Chromagram\n",
    "from encode import Encoder\n",
    "import pickle\n",
    "\n",
    "import risp\n",
    "import neuro\n",
    "import eons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "\n",
    "all_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "\n",
    "all_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.wav')]\n",
    "\n",
    "def parse_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    parts = base_name.split('_')\n",
    "    chord_type = parts[1] \n",
    "    chord_name = parts[2]\n",
    "    root_note_name = parts[3]\n",
    "    return chord_type, chord_name, root_note_name\n",
    "\n",
    "labels = [parse_filename(fname) for fname in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dofo/Repos/Bitbucket/framework/pyframework/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=691\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spike_data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "\n",
    "\n",
    "for wav_path in all_files:\n",
    "    chroma = Chromagram(wav_path)\n",
    "    chroma_array = chroma.chromagram\n",
    "    \n",
    "    # Replicate the directory structure for spike data\n",
    "    relative_path = os.path.relpath(wav_path, data_dir)\n",
    "    spike_filename = os.path.join(spike_data_dir, relative_path.replace('.wav', '.npy'))\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(spike_filename), exist_ok=True)\n",
    "    \n",
    "    # Save the spike data to disk using pickle\n",
    "    np.save(spike_filename, chroma_array)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "\n",
    "chroma_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numerical_labels_for_root(labels):\n",
    "    # Extract root notes\n",
    "    root_notes = [root_note for _, root_note, _ in labels]\n",
    "    \n",
    "    # Get unique root notes and assign a unique number to each\n",
    "    unique_root_notes = sorted(list(set(root_notes)))\n",
    "    root_to_num = {root: i for i, root in enumerate(unique_root_notes)}\n",
    "    \n",
    "    # Convert root notes to numerical labels\n",
    "    numerical_labels = [root_to_num[root] for root in root_notes]\n",
    "    \n",
    "    return numerical_labels, root_to_num\n",
    "\n",
    "# Create numerical labels for root notes\n",
    "y, root_to_num = create_numerical_labels_for_root(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into training+validation and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(chroma_files, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# One-hot encode the labels\n",
    "OneHot = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = OneHot.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_encoded = OneHot.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_encoded = OneHot.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 88)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    def __init__(self, npy_file, Fs=44100, N=2048, H=1024,):\n",
    "\n",
    "        self.Fs = Fs                                            # sampling frequency\n",
    "        self.N = N                                              # FFT size\n",
    "        self.H = H                                              # hop size\n",
    "\n",
    "        self.chromagram = np.load(npy_file)                       # chromagram object for us to call on\n",
    "        \n",
    "        self.num_frames, self.num_bins, self.time_steps = self.get_num_frames() # get number of frames, bins and time steps\n",
    "        \n",
    "        self.chroma_as_list = self._get_chroma()                # chromagram as list\n",
    "        \n",
    "        self.encoder_params = {\n",
    "            \"dmin\": self.num_bins * [0],                        # a list with the length of the number of bins\n",
    "            \"dmax\": self.num_bins * [1],\n",
    "            \"encoders\": [{ \"rate\": { \"subinterval_size\": self.time_steps } }], #if you change stuff, its this line that you're most likely looking for :)\n",
    "            \"interval\": self.time_steps * self.num_frames,      # interval is the length of the song in ms\n",
    "            }\n",
    "        \n",
    "        self.spikes, self.encoder = self._encode()                            # encoded chromagram\n",
    "        \n",
    "     \n",
    "    \n",
    "    def get_num_frames(self):\n",
    "\n",
    "\n",
    "        num_frames = self.chromagram.shape[1]\n",
    "        num_bins = self.chromagram.shape[0]\n",
    "        time_steps = round( (self.H / self.Fs) * 1000, 1)\n",
    "        return num_frames, num_bins, time_steps\n",
    "    \n",
    "    def _get_chroma(self):\n",
    "        chroma = self.chromagram             # chromagram as numpy array\n",
    "        return chroma.tolist()\n",
    "\n",
    "    def _encode(self):\n",
    "        encoder = neuro.EncoderArray(self.encoder_params)       # encoder object. \"neuro.EncoderArray\" from framework\n",
    "        spikes = encoder.get_timeseries_spikes(self.chroma_as_list) # encoded chromagram. \"get_timeseries_spikes\" from framework\n",
    "        return spikes, encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "risp_config = {\n",
    "  \"leak_mode\": \"all\",\n",
    "  \"min_weight\": -1,\n",
    "  \"max_weight\": 1,\n",
    "  \"min_threshold\": -1,\n",
    "  \"max_threshold\": 1,\n",
    "  \"max_delay\": 5,\n",
    "  \"discrete\": False\n",
    "}\n",
    "\n",
    "proc = risp.Processor(risp_config)\n",
    "\n",
    "net = neuro.Network()\n",
    "net.set_properties(proc.get_network_properties())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 12\n",
    "n_hidden = 100\n",
    "n_outputs = 88\n",
    "n_total = n_inputs + n_hidden + n_outputs\n",
    "\n",
    "moa = neuro.MOA()\n",
    "moa.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Node 0 already exists at specified index.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_inputs):\n\u001b[0;32m----> 2\u001b[0m     node \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49madd_node(i)\n\u001b[1;32m      3\u001b[0m     net\u001b[39m.\u001b[39madd_input(i)\n\u001b[1;32m      4\u001b[0m     net\u001b[39m.\u001b[39mrandomize_node_properties(moa,node)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Node 0 already exists at specified index."
     ]
    }
   ],
   "source": [
    "for i in range(n_inputs):\n",
    "    node = net.add_node(i)\n",
    "    net.add_input(i)\n",
    "    net.randomize_node_properties(moa,node)\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    node = net.add_node(n_inputs+i)\n",
    "    net.add_output(i)\n",
    "    net.randomize_node_properties(moa,node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_params = {\n",
    "    \"population_size\": 100,\n",
    "    \"starting_nodes\": n_total,\n",
    "    \"starting_edges\": n_total,\n",
    "    \"multi_edges\": 0.05,\n",
    "    \"merge_rate\": .01,\n",
    "    \"crossover_rate\": 0.5,\n",
    "    \"mutation_rate\": 0.9,\n",
    "    \"add_node_rate\": 0.5,\n",
    "    \"add_edge_rate\": 0.9,\n",
    "    \"delete_node_rate\": 0.4,\n",
    "    \"delete_edge_rate\": 0.8,\n",
    "    \"node_params_rate\": 1.5,\n",
    "    \"edge_params_rate\": 1.5,\n",
    "    \"net_params_rate\": .01,\n",
    "    \"num_mutations\": 5,\n",
    "    \"random_factor\": 0.05,\n",
    "    \"num_best\": 3,\n",
    "\n",
    "    \"selection_type\": \"tournament\",\n",
    "    \"tournament_size_factor\": 0.1,\n",
    "    \"tournament_best_net_factor\": 0.9,\n",
    "    \"node_mutations\": { \"Threshold\": 1.0 },\n",
    "    \"net_mutations\": { },\n",
    "    \"edge_mutations\": { \"Weight\": 0.5, \"Delay\": 0.5 },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolver = eons.EONS(eo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_spike = Encoder(ex1).spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 ='/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords/dom7_ninth/NordGrand1_dom7ninth_G3_55.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.load_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.apply_spikes(Encoder(ex1).spikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyframework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
