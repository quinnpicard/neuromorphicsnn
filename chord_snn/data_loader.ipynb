{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from encode import Chromagram\n",
    "from encode import Encoder\n",
    "import pickle\n",
    "\n",
    "import risp\n",
    "import neuro\n",
    "import eons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_without_octave(note):\n",
    "    return ''.join([char for char in note if not char.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory of chord wav files\n",
    "data_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "\n",
    "#a list of all the wav files in the directory\n",
    "wav_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.wav')]\n",
    "\n",
    "#this function uses the filename to get the chord type, chord name, and root note name\n",
    "def parse_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    root_name = os.path.splitext(base_name)[0]\n",
    "    parts = root_name.split('_')\n",
    "    chord_type = parts[1] \n",
    "    chord_name = parts[2]\n",
    "    midi_note_name = parts[3]\n",
    "    return chord_type, chord_name, midi_note_name\n",
    "\n",
    "#this is chord type, chord name, and root note name for each file in wav_files\n",
    "labels = [parse_filename(fname) for fname in wav_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the directory where the spike data will be saved\n",
    "def create_numerical_labels(labels):\n",
    "    # Extract chord name from labels\n",
    "    chord_name = [chord_name for _, chord_name, _ in labels]\n",
    "    roots = [get_note_without_octave(note) for note in chord_name]\n",
    "    \n",
    "    # Get unique root notes and assign a unique number to each\n",
    "    unique_chord_names = sorted(list(set(chord_name)))\n",
    "    unique_roots = sorted(list(set(roots)))\n",
    "    \n",
    "    chord_to_num = {root: i for i, root in enumerate(unique_chord_names)}\n",
    "    root_to_num = {note: i for i, note in enumerate(unique_roots)}\n",
    "\n",
    "    # Convert root notes to numerical labels\n",
    "    numerical_label_chord_name = [chord_to_num[chord_name] for chord_name in chord_name]\n",
    "    numerical_label_roots = [root_to_num[root] for root in roots]\n",
    "    \n",
    "    return chord_name, roots, chord_to_num, root_to_num, numerical_label_chord_name, numerical_label_roots\n",
    "\n",
    "# Create numerical labels for root notes\n",
    "chord_name, roots, chord_to_num, root_to_num, numerical_label_chord_name, numerical_label_roots = create_numerical_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"chord_name: \", chord_name)\n",
    "print(\"roots: \", roots)\n",
    "print(\"chord_to_num: \", chord_to_num)\n",
    "print(\"root_to_num: \", root_to_num)\n",
    "print(\"numerical_label_chord_name: \", numerical_label_chord_name)\n",
    "print(\"numerical_label_roots: \", numerical_label_roots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the directory where the spike data will be saved\n",
    "spike_data_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "\n",
    "#this for loop goes through each wav file in all_files, creates a chromagram, and saves the chromagram as a numpy array\n",
    "for wav_path in wav_files:\n",
    "    chroma = Chromagram(wav_path)\n",
    "    chroma_array = chroma.chromagram\n",
    "    \n",
    "    # Replicate the directory structure for spike data\n",
    "    relative_path = os.path.relpath(wav_path, data_dir)\n",
    "    spike_filename = os.path.join(spike_data_dir, relative_path.replace('.wav', '.npy'))\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(spike_filename), exist_ok=True)\n",
    "    \n",
    "    # Save the spike data to disk using pickle\n",
    "    np.save(spike_filename, chroma_array)\n",
    "\n",
    "#this is a list of all the spike data files, just like all_\n",
    "chroma_files = [os.path.join(root, fname)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for fname in files if fname.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma files are not needed to make y (aka the labels for training).\n",
    "The chroma making loop is only really needed once. we can call chroma files from the chroma folder. So lets make two classes one for creating/loading chroma files and and one for creating/loadind the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into training+validation and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(chroma_files, numerical_label_roots, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# One-hot encode the labels\n",
    "OneHot = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = OneHot.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_encoded = OneHot.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_encoded = OneHot.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeler_loader:\n",
    "    def __init__(self):\n",
    "        #directory of chord wav files\n",
    "        self.source_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "        #a list of all the wav files in the directory\n",
    "        self.wav_files = self._get_wav_files()\n",
    "        #chord type, chord name, and root note name\n",
    "        self.labels = self._get_labels()\n",
    "        self.numerical_label_chord, self.numerical_label_roots = self.create_numerical_labels(self.labels)\n",
    "        \n",
    "    def _get_wav_files(self):\n",
    "        return [os.path.join(root, fname)\n",
    "                for root, dirs, files in os.walk(self.source_dir)\n",
    "                for fname in files if fname.endswith('.wav')]\n",
    "\n",
    "    #this function uses the filename to get the chord type, chord name, and root note name\n",
    "    def _parse_filename(self, filename):\n",
    "        base_name = os.path.basename(filename)\n",
    "        root_name = os.path.splitext(base_name)[0]\n",
    "        parts = root_name.split('_')\n",
    "        chord_type = parts[1] \n",
    "        chord_name = parts[2]\n",
    "        midi_note_name = parts[3]\n",
    "        return chord_type, chord_name, midi_note_name\n",
    "\n",
    "    #this is chord type, chord name, and root note name for each file in wav_files\n",
    "    def _get_labels(self):\n",
    "        return [self._parse_filename(fname) for fname in self.wav_files]\n",
    "    \n",
    "    def _get_note_without_octave(self, note):\n",
    "        return ''.join([char for char in note if not char.isdigit()])\n",
    "    \n",
    "    \n",
    "    #this is the directory where the spike data will be saved\n",
    "    def create_numerical_labels(self, labels):\n",
    "        # Extract chord name from labels\n",
    "        chord_names = [chord_name for _, chord_name, _ in self.labels]\n",
    "        roots = [self._get_note_without_octave(note) for note in chord_names]\n",
    "        \n",
    "        # Get unique root notes and assign a unique number to each\n",
    "        unique_chord_names = sorted(list(set(chord_names)))\n",
    "        unique_roots = sorted(list(set(roots)))\n",
    "        \n",
    "        chord_to_num = {root: i for i, root in enumerate(unique_chord_names)}\n",
    "        root_to_num = {note: i for i, note in enumerate(unique_roots)}\n",
    "\n",
    "        # Convert root notes to numerical labels\n",
    "        numerical_label_chord = [chord_to_num[chord] for chord in chord_names]\n",
    "        numerical_label_roots = [root_to_num[root] for root in roots]\n",
    "        \n",
    "        return numerical_label_chord, numerical_label_roots\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chroma_loader:\n",
    "    def __init__(self):\n",
    "        #this is the directory where the spike data will be saved\n",
    "        self.destination_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "        self.chroma_files = self._get_chroma_files()\n",
    "\n",
    "    #this for loop goes through each wav file in all_files, creates a chromagram, and saves the chromagram as a numpy array\n",
    "    def create_npy_chroma(self):\n",
    "        for wav_path in labeler_loader().wav_files:\n",
    "            chroma = Chromagram(wav_path)\n",
    "            chroma_array = chroma.chromagram\n",
    "            \n",
    "            # Replicate the directory structure for spike data\n",
    "            relative_path = os.path.relpath(wav_path, labeler_loader().source_dir)\n",
    "            spike_filename = os.path.join(self.destination_dir, relative_path.replace('.wav', '.npy'))\n",
    "            \n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(os.path.dirname(spike_filename), exist_ok=True)\n",
    "            \n",
    "            # Save the spike data to disk using pickle\n",
    "            np.save(spike_filename, chroma_array)\n",
    "            \n",
    "    def _get_chroma_files(self):\n",
    "        return [os.path.join(root, fname)\n",
    "                for root, dirs, files in os.walk(labeler_loader().source_dir)\n",
    "                for fname in files if fname.endswith('.npy')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader:\n",
    "    def __init__(self):\n",
    "        #directories used\n",
    "        self.source_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/chords\"\n",
    "        self.destination_dir = \"/home/dofo/Desktop/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords\"\n",
    "        #lists of files\n",
    "        self.wav_files = self._get_files(self.source_dir, '.wav')\n",
    "        self.chroma_files = self._get_files(self.destination_dir, '.npy') #We use this in training\n",
    "        #labels and numerical labels\n",
    "        self.labels = self._get_labels()      \n",
    "        self.y, self.root_to_num = self.create_numerical_labels(self.labels) #We use this in training\n",
    "        \n",
    "    def _get_files(self, directory, extension):\n",
    "        return [os.path.join(root, fname)\n",
    "                for root, dirs, files in os.walk(directory)\n",
    "                for fname in files if fname.endswith(extension)]\n",
    "\n",
    "    def _parse_filename(self, filename):\n",
    "        base_name = os.path.basename(filename)\n",
    "        root_name = os.path.splitext(base_name)[0]\n",
    "        parts = root_name.split('_')\n",
    "        chord_type = parts[1] \n",
    "        chord_name = parts[2]\n",
    "        midi_note_name = parts[3]\n",
    "        return chord_type, chord_name, midi_note_name\n",
    "    #this is chord type, chord name, and root note name for each file in wav_files\n",
    "    def _get_labels(self):\n",
    "        return [self._parse_filename(fname) for fname in self.wav_files]\n",
    "    \n",
    "    def _get_note_without_octave(self, note):\n",
    "        return ''.join([char for char in note if not char.isdigit()])\n",
    "    \n",
    "    #this is the directory where the spike data will be saved\n",
    "    def create_numerical_labels(self, labels):\n",
    "        # Extract chord name from labels\n",
    "        chord_names = [chord_name for _, chord_name, _ in self.labels]\n",
    "        roots = [self._get_note_without_octave(note) for note in chord_names]\n",
    "        \n",
    "        # Get unique root notes and assign a unique number to each\n",
    "        unique_chord_names = sorted(list(set(chord_names)))\n",
    "        unique_roots = sorted(list(set(roots)))\n",
    "        \n",
    "        chord_to_num = {root: i for i, root in enumerate(unique_chord_names)}\n",
    "        root_to_num = {note: i for i, note in enumerate(unique_roots)}\n",
    "\n",
    "        # Convert root notes to numerical labels\n",
    "        numerical_label_chord = [chord_to_num[chord] for chord in chord_names]\n",
    "        numerical_label_roots = [root_to_num[root] for root in roots]\n",
    "        \n",
    "        return numerical_label_chord, numerical_label_roots               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risp_config = {\n",
    "  \"leak_mode\": \"all\",\n",
    "  \"min_weight\": -1,\n",
    "  \"max_weight\": 1,\n",
    "  \"min_threshold\": -1,\n",
    "  \"max_threshold\": 1,\n",
    "  \"max_delay\": 5,\n",
    "  \"discrete\": False\n",
    "}\n",
    "\n",
    "proc = risp.Processor(risp_config)\n",
    "\n",
    "net = neuro.Network()\n",
    "net.set_properties(proc.get_network_properties())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 12\n",
    "n_hidden = 100\n",
    "n_outputs = 88\n",
    "n_total = n_inputs + n_hidden + n_outputs\n",
    "\n",
    "moa = neuro.MOA()\n",
    "moa.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_inputs):\n",
    "    node = net.add_node(i)\n",
    "    net.add_input(i)\n",
    "    net.randomize_node_properties(moa,node)\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    node = net.add_node(n_inputs+i)\n",
    "    net.add_output(i)\n",
    "    net.randomize_node_properties(moa,node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_params = {\n",
    "    \"population_size\": 100,\n",
    "    \"starting_nodes\": n_total,\n",
    "    \"starting_edges\": n_total,\n",
    "    \"multi_edges\": 0.05,\n",
    "    \"merge_rate\": .01,\n",
    "    \"crossover_rate\": 0.5,\n",
    "    \"mutation_rate\": 0.9,\n",
    "    \"add_node_rate\": 0.5,\n",
    "    \"add_edge_rate\": 0.9,\n",
    "    \"delete_node_rate\": 0.4,\n",
    "    \"delete_edge_rate\": 0.8,\n",
    "    \"node_params_rate\": 1.5,\n",
    "    \"edge_params_rate\": 1.5,\n",
    "    \"net_params_rate\": .01,\n",
    "    \"num_mutations\": 5,\n",
    "    \"random_factor\": 0.05,\n",
    "    \"num_best\": 3,\n",
    "\n",
    "    \"selection_type\": \"tournament\",\n",
    "    \"tournament_size_factor\": 0.1,\n",
    "    \"tournament_best_net_factor\": 0.9,\n",
    "    \"node_mutations\": { \"Threshold\": 1.0 },\n",
    "    \"net_mutations\": { },\n",
    "    \"edge_mutations\": { \"Weight\": 0.5, \"Delay\": 0.5 },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 ='/home/dofo/Repos/Github/neuromorphicsnn/chord_snn/dataset/npy_chroma_chords/dom7_ninth/NordGrand1_dom7ninth_G3_55.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolver = eons.EONS(eo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_spike = Encoder(ex1).spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.load_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.apply_spikes(ex1_spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: see what the output of proc is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = {\n",
    "    \"dmin\": [-1],\n",
    "    \"dmax\": [1.5],\n",
    "    \"encoders\": [{ \"rate\": { \"subinterval_size\": 1 } }],\n",
    "    \"interval\": 8.8,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = neuro.EncoderArray(encoder_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyframework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
