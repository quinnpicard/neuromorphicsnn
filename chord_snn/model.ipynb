{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import neuro\n",
    "import risp\n",
    "import random\n",
    "\n",
    "from encode import Chromagram\n",
    "from encode import Encoder\n",
    "from data_loader import data_loader\n",
    "import risp\n",
    "import neuro\n",
    "import eons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Innitialize the neuroprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "risp_config = {\n",
    "  \"leak_mode\": \"all\",\n",
    "  \"min_weight\": -1,\n",
    "  \"max_weight\": 1,\n",
    "  \"min_threshold\": -1,\n",
    "  \"max_threshold\": 1,\n",
    "  \"max_delay\": 5,\n",
    "  \"discrete\": False\n",
    "}\n",
    "\n",
    "proc = risp.Processor(risp_config) # RISP processor\n",
    "\n",
    "net = neuro.Network() # Neuro network\n",
    "net.set_properties(proc.get_network_properties()) # Set network properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the data into training+validation and testing sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(data_loader().chroma_files, data_loader().numerical_label_roots, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# One-hot encode the labels\n",
    "OneHot = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = OneHot.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_encoded = OneHot.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_encoded = OneHot.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) create template for eons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 12\n",
    "n_hidden = 360\n",
    "n_outputs = 12\n",
    "n_neurons = n_inputs + n_hidden + n_outputs\n",
    "n_synapses = 1000\n",
    "\n",
    "\n",
    "moa = neuro.MOA()\n",
    "moa.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron(neuron_id, net, moa):\n",
    "    neuron = net.add_node(neuron_id)\n",
    "    net.randomize_node_properties(moa, neuron)\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_inputs):\n",
    "    neuron = create_neuron(i, net, moa)\n",
    "    neuron.set(\"Threshold\",0.75)\n",
    "    net.add_input(i)\n",
    "    \n",
    "for i in range(n_outputs):\n",
    "    neuron = create_neuron(i+n_inputs, net, moa)\n",
    "    neuron.set(\"Threshold\",0.75)\n",
    "    net.add_output(i)\n",
    "    \n",
    "for i in range(n_hidden):\n",
    "    neuron = create_neuron(i+n_inputs+n_outputs, net, moa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 0's input ID: 0\n",
      "Neuron 1's input ID: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Neuron 0's input ID:\", net.get_node(0).input_id)\n",
    "print(\"Neuron 1's input ID:\", net.get_node(1).input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_synapses):\n",
    "    source = random.randint(0,n_neurons-1)\n",
    "    dest = random.randint(0,n_neurons-1)\n",
    "    synapse = net.add_or_get_edge(source, dest)\n",
    "    net.randomize_edge_properties(moa, synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) set up the eons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_params = {\n",
    "    \"population_size\": 100,\n",
    "    \"starting_nodes\": n_neurons,\n",
    "    \"starting_edges\": n_neurons,\n",
    "    \"multi_edges\": 0.05,\n",
    "    \"merge_rate\": .01,\n",
    "    \"crossover_rate\": 0.5,\n",
    "    \"mutation_rate\": 0.9,\n",
    "    \"add_node_rate\": 0.5,\n",
    "    \"add_edge_rate\": 0.9,\n",
    "    \"delete_node_rate\": 0.4,\n",
    "    \"delete_edge_rate\": 0.8,\n",
    "    \"node_params_rate\": 1.5,\n",
    "    \"edge_params_rate\": 1.5,\n",
    "    \"net_params_rate\": .01,\n",
    "    \"num_mutations\": 5,\n",
    "    \"random_factor\": 0.05,\n",
    "    \"num_best\": 3,\n",
    "\n",
    "    \"selection_type\": \"tournament\",\n",
    "    \"tournament_size_factor\": 0.1,\n",
    "    \"tournament_best_net_factor\": 0.9,\n",
    "    \"node_mutations\": { \"Threshold\": 1.0 },\n",
    "    \"net_mutations\": { },\n",
    "    \"edge_mutations\": { \"Weight\": 0.5, \"Delay\": 0.5 },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolver = eons.EONS(eo_params)\n",
    "evolver.set_template_network(net)\n",
    "\n",
    "pop = evolver.generate_population(eo_params,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(proc, x):\n",
    "    # Load the chroma data from the npy file\n",
    "    encoder=Encoder(x)\n",
    "    \n",
    "    proc.clear_activity()\n",
    "    proc.apply_spikes(encoder.spikes)\n",
    "    proc.run(encoder.time_steps * encoder.num_bins) # you might adjust this duration based on your needs\n",
    "    \n",
    "    # Decoding the output to get the predicted label. You might need to adjust this\n",
    "    predicted_index = proc.output_count_max(n_outputs)[0]\n",
    "    # Convert index to one-hot encoded format\n",
    "    one_hot_prediction = np.zeros(n_outputs)\n",
    "    one_hot_prediction[predicted_index] = 1.0\n",
    "    \n",
    "    return one_hot_prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(proc, net, X, y):\n",
    "    proc.load_network(net)\n",
    "    \n",
    "    # Set up output tracking\n",
    "    for i in range(n_outputs):\n",
    "        proc.track_neuron_events(i)\n",
    "    \n",
    "    y_predict = [get_prediction(proc, x) for x in X]\n",
    "    return accuracy_score(y_predict, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generations = 100\n",
    "vals = []\n",
    "\n",
    "for generation in range(max_generations):\n",
    "    # Evaluate fitness of all networks in the population\n",
    "    fitnesses = [fitness(proc, net.network, X_train, y_train_encoded) for net in pop.networks]\n",
    "    \n",
    "    # Track and print best fitness in the current generation\n",
    "    best_fitness = max(fitnesses)\n",
    "    vals.append(best_fitness)\n",
    "    print(f\"Generation {generation + 1} Best Fitness: {best_fitness:.4f}\")\n",
    "    \n",
    "    # Produce the next generation based on the current population's fitness\n",
    "    pop = evolver.do_epoch(pop, fitnesses, eo_params)\n",
    "\n",
    "# Optionally, you can evaluate and print the performance of the best network on the test set here.\n",
    "\n",
    "print(\"Evolution finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyframework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
