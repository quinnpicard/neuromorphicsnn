{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wave\n",
    "import os \n",
    "from scipy.signal import find_peaks\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_audio(file_path, sr=22050, duration=None):\n",
    "    try:\n",
    "        y, _ = torchaudio.load(file_path)\n",
    "        # Resample if necessary\n",
    "        if sr is not None:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=_, new_freq=sr)\n",
    "            y = resampler(y)\n",
    "        if duration is not None:\n",
    "            y = y[:, :int(sr*duration)]\n",
    "        return y.squeeze().numpy()\n",
    "    except RuntimeError:\n",
    "        print(f\"Error: Failed to load audio from {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def latency_coding(audio_signal, threshold=0.5, duration=50):\n",
    "    # Convert audio_signal to a PyTorch tensor if it's not already\n",
    "    audio_signal = torch.tensor(audio_signal) if not isinstance(audio_signal, torch.Tensor) else audio_signal\n",
    "    \n",
    "    # Normalize the audio signal to [0, 1]\n",
    "    audio_signal = (audio_signal - audio_signal.min()) / (audio_signal.max() - audio_signal.min())\n",
    "    \n",
    "    # Calculate the spike time based on intensity\n",
    "    spike_times = (1 - audio_signal) * duration\n",
    "    spike_times = spike_times.long()\n",
    "    \n",
    "    # Generate spike trains\n",
    "    spike_trains = torch.zeros(duration, len(audio_signal))\n",
    "    for i in range(len(audio_signal)):\n",
    "        if spike_times[i] < duration:\n",
    "            spike_trains[spike_times[i], i] = 1.0\n",
    "            \n",
    "    return spike_trains\n",
    "\n",
    "\n",
    "\n",
    "def extract_label_from_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    label = base_name.split('.')[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, sr=22050, threshold=0.5, duration=50):\n",
    "        self.audio_files = audio_files\n",
    "        self.sr = sr\n",
    "        self.threshold = threshold\n",
    "        self.duration = duration\n",
    "        \n",
    "        # Load audio files and filter out None values\n",
    "        self.audio_data = [(f, load_audio(f, sr, duration)) for f in audio_files]\n",
    "        self.audio_data = [(f, data) for f, data in self.audio_data if data is not None]\n",
    "        \n",
    "        self.labels = [extract_label_from_filename(f) for f, _ in self.audio_data]\n",
    "        \n",
    "        # Determine the length of the smallest audio file\n",
    "        self.min_length = min([len(data) for _, data in self.audio_data])\n",
    "        print(f\"Length of the smallest audio file: {self.min_length}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, audio_signal = self.audio_data[idx]\n",
    "        \n",
    "        # Trim the audio signal to the length of the smallest file\n",
    "        audio_signal = audio_signal[:self.min_length]\n",
    "        \n",
    "        spike_trains = latency_coding(audio_signal, self.threshold, self.duration)\n",
    "        label = extract_label_from_filename(file_path)\n",
    "        return spike_trains, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to load audio from snnTorch_audio/jazz.00054.wav\n",
      "Length of the smallest audio file: 660000\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all .wav files in the specified directory\n",
    "folder_path = \"snnTorch_audio\"\n",
    "audio_files = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "\n",
    "dataset = AudioDataset(audio_files)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spikes, labels in dataloader:\n",
    "    # Use spikes and labels in your training loop\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
