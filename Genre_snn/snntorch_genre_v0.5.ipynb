{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wave\n",
    "import os \n",
    "from scipy.signal import find_peaks\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# layer parameters\n",
    "batch_size = 1\n",
    "n_mels = 80\n",
    "\n",
    "num_hidden = 20\n",
    "num_outputs = 2\n",
    "beta = 0.9\n",
    "num_inputs = n_mels\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_mel_spectrogram(file_path, sr=22050/16, n_mels=n_mels, duration=None):\n",
    "    try:\n",
    "        y, _ = torchaudio.load(file_path)\n",
    "        if sr is not None:\n",
    "            resampler = T.Resample(orig_freq=_, new_freq=sr)\n",
    "            y = resampler(y)\n",
    "        if duration is not None:\n",
    "            y = y[:, :int(sr*duration)]\n",
    "        \n",
    "        mel_transform = T.MelSpectrogram(sample_rate=sr, n_mels=n_mels)\n",
    "        mel_spectrogram = mel_transform(y)\n",
    "        \n",
    "        return mel_spectrogram.squeeze().numpy()\n",
    "    except RuntimeError:\n",
    "        print(f\"Error: Failed to load audio from {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def latency_coding(audio_signal, threshold=0.5, duration=50):\n",
    "    # Convert audio_signal to a PyTorch tensor if it's not already\n",
    "    audio_signal = torch.tensor(audio_signal) if not isinstance(audio_signal, torch.Tensor) else audio_signal\n",
    "    \n",
    "    # Normalize the audio signal to [0, 1]\n",
    "    audio_signal = (audio_signal - audio_signal.min()) / (audio_signal.max() - audio_signal.min())\n",
    "    \n",
    "    # Calculate the spike time based on intensity\n",
    "    spike_times = (1 - audio_signal) * duration\n",
    "    spike_times = spike_times.long()\n",
    "    \n",
    "    # Generate spike trains\n",
    "    spike_trains = torch.zeros(duration, len(audio_signal))\n",
    "    for i in range(len(audio_signal)):\n",
    "        if spike_times[i] < duration:\n",
    "            spike_trains[spike_times[i], i] = 1.0\n",
    "            \n",
    "    return spike_trains\n",
    "\n",
    "\n",
    "\n",
    "def extract_label_from_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    label = base_name.split('.')[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, sr=22050, threshold=0.5, duration=50, n_mels=40):\n",
    "    \n",
    "\n",
    "        self.audio_files = audio_files\n",
    "        self.sr = sr\n",
    "        self.threshold = threshold\n",
    "        self.duration = duration\n",
    "        self.n_mels = n_mels\n",
    "        \n",
    "        # Load audio files and filter out None values\n",
    "        self.audio_data = [(f, load_mel_spectrogram(f, sr, n_mels, duration)) for f in audio_files]\n",
    "        self.audio_data = [(f, data) for f, data in self.audio_data if data is not None]\n",
    "        \n",
    "        self.labels = [extract_label_from_filename(f) for f, _ in self.audio_data]\n",
    "        \n",
    "        # Determine the length of the smallest audio file\n",
    "        self.min_length = min([data.shape[1] for _, data in self.audio_data])\n",
    "        print(f\"Length of the smallest audio file (in Mel bins): {self.min_length}\")\n",
    "\n",
    "        unique_labels = list(set(self.labels))\n",
    "        self.label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "        self.int_to_label = {i: label for label, i in self.label_to_int.items()}\n",
    "        self.encoded_labels = [self.label_to_int[label] for label in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, mel_spectrogram = self.audio_data[idx]\n",
    "        \n",
    "        # Trim the Mel-spectrogram to the length of the smallest file\n",
    "        mel_spectrogram = mel_spectrogram[:, :self.min_length]\n",
    "        \n",
    "        spike_trains = latency_coding(mel_spectrogram.flatten(), self.threshold)\n",
    "        #label = extract_label_from_filename(file_path)\n",
    "        encoded_label = self.encoded_labels[idx]\n",
    "        return spike_trains, encoded_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the smallest audio file (in Mel bins): 3309\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all .wav files in the specified directory\n",
    "folder_path = \"snnTorch_audio\"\n",
    "audio_files = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "\n",
    "\n",
    "dataset = AudioDataset(audio_files)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        \n",
    "        # Record the final layer\n",
    "        spk1_rec = []\n",
    "        mem1_rec = []\n",
    "        \n",
    "        # Use expected_num_steps here\n",
    "        for step in range(x.size(1)):  # This will automatically adjust to the size of the input data\n",
    "            cur1 = self.fc1(x[:, step, :])  # Index the data tensor here\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            spk1_rec.append(spk1)\n",
    "            mem1_rec.append(mem1)\n",
    "        \n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(mem1_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6618000\n",
      "82725\n",
      "torch.Size([82725, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "data, targets = next(iter(dataloader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Reshape the data tensor\n",
    "data, targets = next(iter(dataloader))\n",
    "flattened_size = data.numel()\n",
    "print(flattened_size)\n",
    "expected_num_steps = flattened_size // (batch_size * num_inputs)\n",
    "print(expected_num_steps)\n",
    "data = data.view(batch_size, expected_num_steps, num_inputs)\n",
    "\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Reshape the data tensor\n",
    "#data = data.view(batch_size, num_steps, -1)\n",
    "#data = data.view(batch_size, expected_num_steps, num_inputs)\n",
    "\n",
    "spk_rec, mem_rec = net(data)\n",
    "print(mem_rec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 571.4331\n",
      "Epoch [2/10], Loss: 76.5000\n",
      "Epoch [3/10], Loss: 46.5000\n",
      "Epoch [4/10], Loss: 15.5001\n",
      "Epoch [5/10], Loss: 23.3018\n",
      "Epoch [6/10], Loss: 34.5000\n",
      "Epoch [7/10], Loss: 33.8313\n",
      "Epoch [8/10], Loss: 16.0321\n",
      "Epoch [9/10], Loss: 22.2000\n",
      "Epoch [10/10], Loss: 41.2000\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Reshape the data tensor\n",
    "        flattened_size = data.numel()\n",
    "        expected_num_steps = flattened_size // (batch_size * num_inputs)\n",
    "        data = data.view(batch_size, expected_num_steps, num_inputs)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(data)\n",
    "        # Sum the spikes over time and get the neuron with the highest number of spikes\n",
    "        outputs_sum = outputs.sum(dim=0)\n",
    "\n",
    "        # Print shapes of outputs_sum and targets for debugging\n",
    "        #print(\"outputs_sum shape:\", outputs_sum.shape)\n",
    "        #print(\"targets shape:\", targets.shape)\n",
    "\n",
    "        # Print some example target values for debugging\n",
    "        #print(\"Targets:\", targets)\n",
    "\n",
    "        # Check the shapes of the individual outputs for a single batch element\n",
    "        #for i, output in enumerate(outputs):\n",
    "            #print(f\"Output {i} shape:\", output.shape)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(outputs_sum, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norm\n",
    "        clip_grad_norm_(net.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
